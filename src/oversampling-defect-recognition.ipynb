{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"GLOBAL_SEED = 744\n\nimport os\nos.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n\nimport numpy as np\nimport tensorflow as tf\nimport random\n\n\nnp.random.seed(GLOBAL_SEED)\nrandom.seed(GLOBAL_SEED)\n\nfrom keras import backend as K\ntf.random.set_seed(GLOBAL_SEED)\n\nconfig = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nconfig.gpu_options.allow_growth = True\nsess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\nK.set_session(sess)\n\nimport torch\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.manual_seed(GLOBAL_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:38.681933Z","iopub.execute_input":"2022-06-08T09:57:38.682445Z","iopub.status.idle":"2022-06-08T09:57:50.637820Z","shell.execute_reply.started":"2022-06-08T09:57:38.682355Z","shell.execute_reply":"2022-06-08T09:57:50.636797Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### After initializng seeds for reproducibility import the BigGAN based generator","metadata":{}},{"cell_type":"code","source":"!cp ../input/biggan-generator-v3/biggan_generator.py ./\n!cp ../input/biggan-generator-v3/generate_images.py ./\n\nimport sys\nsys.path.insert(0, './')","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:50.640154Z","iopub.execute_input":"2022-06-08T09:57:50.640980Z","iopub.status.idle":"2022-06-08T09:57:52.173351Z","shell.execute_reply.started":"2022-06-08T09:57:50.640922Z","shell.execute_reply":"2022-06-08T09:57:52.171894Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import recall_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Activation, BatchNormalization\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nfrom tensorflow.keras.optimizers import Adam\nimport warnings\nimport os\nimport shutil\nfrom PIL import ImageFile\nfrom PIL import Image\nimport pandas as pd\nfrom pandas import DataFrame\nfrom scipy.stats import entropy\nfrom scipy.special import softmax\nfrom heapq import nlargest, nsmallest\nfrom operator import itemgetter\nimport generate_images","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:52.175697Z","iopub.execute_input":"2022-06-08T09:57:52.176242Z","iopub.status.idle":"2022-06-08T09:57:53.183017Z","shell.execute_reply.started":"2022-06-08T09:57:52.176189Z","shell.execute_reply":"2022-06-08T09:57:53.181900Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Create directory structures and define constants","metadata":{}},{"cell_type":"code","source":"DRY_RUN = True # True to quickly check everything is working properly\n\nimg_rows, img_cols = 128, 128 #original: 220, 360\n\nsrc_dir = '../input/shaver-shell-full-all-classes-v2/shaver-shell-full'\ntrain_path = './train/'\nvalidation_path = './validation/'\ntest_path = './test/'\n\nclass_double_print = '19-01 dubbeldruk'\nclass_good = '19-01 goed'\nclass_interrupted = '19-01 onderbroken'\nall_classes = [class_double_print, class_good, class_interrupted]\n\nmodel_path = './models/custom_cnn.h5'","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.187282Z","iopub.execute_input":"2022-06-08T09:57:53.187600Z","iopub.status.idle":"2022-06-08T09:57:53.197942Z","shell.execute_reply.started":"2022-06-08T09:57:53.187571Z","shell.execute_reply":"2022-06-08T09:57:53.195607Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Define the custom CNN model used for defect classification","metadata":{}},{"cell_type":"code","source":"input_shape = (img_rows, img_cols, 3)\n\ndef conv_net(conv_blocks = 1, filter_size = (3,3), no_filters = 16, is_init = True, is_last = True):\n    convnet = Sequential()\n    if is_init:\n        convnet.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=input_shape))\n        convnet.add(tf.keras.layers.experimental.preprocessing.Normalization())\n    for i in range(conv_blocks):\n        convnet.add(Conv2D(no_filters,filter_size,padding='same'))\n        convnet.add(BatchNormalization())\n        convnet.add(Activation('relu'))\n        convnet.add(tf.keras.layers.Dropout(0.4))\n        convnet.add(MaxPooling2D())\n    if is_last:\n        convnet.add(Flatten())\n        return convnet\n\ndef create_model():  \n    inp = Input(input_shape)\n\n    base = conv_net()(inp)\n    detailed = conv_net(conv_blocks = 1, filter_size = (1,1), is_last = True)(inp)\n\n    concat_layer = tf.concat([base, detailed], axis = 1)\n    out = keras.layers.Dense(len(all_classes), activation=\"softmax\", \n                         kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.0001, l2=0.0001))(concat_layer)\n\n    model = Model([inp], out)\n    optimizer = Adam(0.00001)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.199428Z","iopub.execute_input":"2022-06-08T09:57:53.199869Z","iopub.status.idle":"2022-06-08T09:57:53.219301Z","shell.execute_reply.started":"2022-06-08T09:57:53.199800Z","shell.execute_reply":"2022-06-08T09:57:53.218203Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Calculation of examined metrics","metadata":{}},{"cell_type":"code","source":"def calc_metrics(y_true, y_pred, y_proba):\n    y_good = (y_true == all_classes.index('19-01 goed')).astype(int)\n    y_double_print = (y_true == all_classes.index('19-01 dubbeldruk')).astype(int)\n    y_interrupted = (y_true == all_classes.index('19-01 onderbroken')).astype(int)\n    res = {'binary_roc_auc': roc_auc_score(y_good, y_proba[:, all_classes.index('19-01 goed')]),\n            'binary_recall': recall_score(y_good, (y_pred == all_classes.index('19-01 goed')).astype(int), pos_label=0),\n            'multiclass_roc_auc': roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted'),\n            'recall_double_print': recall_score(y_double_print, (y_pred == all_classes.index('19-01 dubbeldruk')).astype(int), pos_label=1),\n            'recall_interrupted': recall_score(y_interrupted, (y_pred == all_classes.index('19-01 onderbroken')).astype(int), pos_label=1),\n           }\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.221089Z","iopub.execute_input":"2022-06-08T09:57:53.222399Z","iopub.status.idle":"2022-06-08T09:57:53.233941Z","shell.execute_reply.started":"2022-06-08T09:57:53.222256Z","shell.execute_reply":"2022-06-08T09:57:53.232803Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Utils for copying train, validation and test files from the input dataset to the train and test files following the current split","metadata":{}},{"cell_type":"code","source":"def copy_split_images(X, Y, dest, val_path):\n    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=GLOBAL_SEED)\n    copy_images(X_train, Y_train, dest)\n    copy_images(X_val, Y_val, val_path)\n    \n\ndef copy_images(X, Y, dest):\n    for eachIndex in range(len(X)):\n        label=''\n        for i in range(len(all_classes)):\n            if(Y[eachIndex]==i):\n                label=all_classes[i]\n        shutil.copy(os.path.join(src_dir, label, X[eachIndex]), \n                    os.path.join(dest, label, X[eachIndex]))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.236123Z","iopub.execute_input":"2022-06-08T09:57:53.236952Z","iopub.status.idle":"2022-06-08T09:57:53.249714Z","shell.execute_reply.started":"2022-06-08T09:57:53.236875Z","shell.execute_reply":"2022-06-08T09:57:53.248596Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Code to generate synthetic images calling biggan_generator.py","metadata":{}},{"cell_type":"code","source":"def generate_aug_images(X, dest, n_aug):\n    generate_images.generate_images(dataset_root = src_dir, \n                    weights_path = '../input/biggan-weights/138k/G_ema.pth', \n                    AUGMENTATION_TARGET = n_aug, \n                    savedir = dest, \n                    no_images_to_generate = len(X), \n                    GLOBAL_SEED = GLOBAL_SEED,\n                    start_image = 0, \n                    filter_set = [x.split('/')[1] for x in X]\n                   )\n\ndef get_aug_images(X, Y, Y_train, dest):\n    n_aug = 2*len([y for y in Y_train if y==1]) # good images are have class index = 1\n    print('N_AUG: ', n_aug)\n    generate_aug_images(X, dest, n_aug)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.251856Z","iopub.execute_input":"2022-06-08T09:57:53.252769Z","iopub.status.idle":"2022-06-08T09:57:53.263154Z","shell.execute_reply.started":"2022-06-08T09:57:53.252726Z","shell.execute_reply":"2022-06-08T09:57:53.261969Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Confidence calculation based on the distance to boundary (needs to be called inside a  tf.GradientTape context)","metadata":{}},{"cell_type":"code","source":"def get_all_layers(model):\n    all_layers = []\n    for layer in model.layers[1:]:\n        if 'sequential' in layer.name:\n            sub_layers = model.get_layer(layer.name).layers\n            for sub_l in sub_layers:\n                if ('conv' in sub_l.name) or ('dense' in sub_l.name):\n                    all_layers.append(sub_l)\n        elif ('conv' in layer.name) or ('dense' in layer.name):\n            all_layers.append(layer)\n    return all_layers\n\n\ndef distance_to_boundary(y_pred, y_true, model, tape):\n    correct_class_prob = y_pred[y_true]\n    good_class_prob = y_pred[1] #good class has index 1\n    \n    difference_prob = abs(correct_class_prob - good_class_prob)\n    \n    norm_fn = lambda x: tf.norm(x, ord=np.inf)\n    \n    model_layers = get_all_layers(model)\n    \n    dists_list = []\n    \n    for layer in model_layers:\n        wt = layer.trainable_weights\n        if len(wt) > 0:\n            wt = wt[0]\n        flatten_layer = Flatten()\n                \n        difference_prob_grad = flatten_layer(tape.gradient(difference_prob, wt)[tf.newaxis, :])\n        \n        norm_term = tf.map_fn(norm_fn, difference_prob_grad)\n        \n        difference_prob_gradnorm = norm_term / wt\n        \n        epsilon = 0.00001\n        distance_to_boundary = difference_prob / (difference_prob_gradnorm + epsilon)\n        dists_list.append(tf.reduce_mean(distance_to_boundary))\n        \n        final_dist = tf.reduce_mean(dists_list)\n        \n    return abs(final_dist.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.264784Z","iopub.execute_input":"2022-06-08T09:57:53.265994Z","iopub.status.idle":"2022-06-08T09:57:53.283404Z","shell.execute_reply.started":"2022-06-08T09:57:53.265951Z","shell.execute_reply":"2022-06-08T09:57:53.282128Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### pick_aug_images utilizes the above distance to boundary calculation to pick the top_k images with the smallest distance (lowest confidence) and their labels","metadata":{}},{"cell_type":"code","source":"def pick_aug_images(model, train_generator, defect_class_recalls, top_k = 10):\n    true_classes = train_generator.classes\n    true_classes = tf.Variable(true_classes)\n    filenames = train_generator.filenames\n    batch_size = train_generator.batch_size\n    \n    n_batches = len(filenames)//batch_size\n\n    confidence_scores_double_print = []\n    confidence_scores_interrupted = []\n    \n    for i in range(n_batches):\n        img_batch, _ = train_generator.next()\n        img_batch = tf.Variable(img_batch)\n        \n        recall_double = defect_class_recalls['recall_double_print']\n        recall_interrupted = defect_class_recalls['recall_interrupted']\n    \n        with tf.GradientTape(persistent=True) as tape:\n            train_predictions = model(img_batch)\n            for j in range(batch_size):\n                current_idx = i*batch_size + j\n                pred = train_predictions[j]\n                conf = distance_to_boundary(pred, true_classes.value()[current_idx], model, tape)\n                \n                #perform augmentation only for minority classes with indexes 0 and 2\n                if true_classes.value()[current_idx] == 0: \n                    confidence_scores_double_print.append((filenames[current_idx], true_classes.value()[current_idx], pred, conf))\n                elif true_classes.value()[current_idx] == 2:\n                    confidence_scores_interrupted.append((filenames[current_idx], true_classes.value()[current_idx], pred, conf))\n        del tape\n        \n    all_confidence_scores = confidence_scores_double_print + confidence_scores_interrupted\n    top_items = nsmallest(top_k, all_confidence_scores, key=itemgetter(3))\n        \n    top_paths = [t[0] for t in top_items]\n    top_labels = [t[1] for t in top_items]\n    return top_paths, top_labels","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.287591Z","iopub.execute_input":"2022-06-08T09:57:53.288668Z","iopub.status.idle":"2022-06-08T09:57:53.303114Z","shell.execute_reply.started":"2022-06-08T09:57:53.288621Z","shell.execute_reply":"2022-06-08T09:57:53.301881Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### Load image paths in X and corresponding class labels to Y","metadata":{}},{"cell_type":"code","source":"X=[]\nY=[]\n\nfor i in range(len(all_classes)):\n    source_files=os.listdir(os.path.join(src_dir, all_classes[i]))\n    for f in source_files:\n        X.append(f)\n        Y.append(i)\n\nX=np.asarray(X)\nY=np.asarray(Y)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.304781Z","iopub.execute_input":"2022-06-08T09:57:53.305541Z","iopub.status.idle":"2022-06-08T09:57:53.816150Z","shell.execute_reply.started":"2022-06-08T09:57:53.305481Z","shell.execute_reply":"2022-06-08T09:57:53.815139Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### The 'main' part of the code where the classifier is pre-trained for EPOCHS_PRE_TRAIN epochs and then trained for an additional EPOCHS_TRAIN epochs with confidence-based augmentation ","metadata":{}},{"cell_type":"code","source":"if DRY_RUN:\n    EPOCHS_PRE_TRAIN = 2\n    EPOCHS_TRAIN = 2\n    TOP_K = 3\nelse:\n    EPOCHS_PRE_TRAIN = 20\n    EPOCHS_TRAIN = 30\n    TOP_K = 15\n\n\n# ===============Stratified K-Fold======================\n\nbatch_size = 4\nval_split = 0.2\ntest_split = 0.2\n\nall_results = []\n\nfoldNum=0\n\n#Remove old split\nif os.path.exists(train_path):\n    shutil.rmtree(train_path)\nif os.path.exists(validation_path):\n    shutil.rmtree(validation_path)\nif os.path.exists(test_path):\n    shutil.rmtree(test_path)\n    \n#Recreate paths\nfor label in all_classes:\n    os.makedirs( train_path+label, exist_ok = True)\n    os.makedirs( validation_path+label, exist_ok = True)\n    os.makedirs( test_path+label, exist_ok = True)\n    \nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_split, random_state=GLOBAL_SEED)\n    \n# Copy train images of this keep and fold from full_data to the train folder\ncopy_split_images(X_train, Y_train, train_path, validation_path)\n    \n# Copy validation images of this fold from full_data folder to the validation folder\ncopy_images(X_test, Y_test, test_path)\n        \n# Create data loaders\ntrain_datagen = ImageDataGenerator(validation_split=val_split)\nvalidation_datagen = ImageDataGenerator(validation_split=val_split)\ntest_datagen = ImageDataGenerator()\n        \n    \ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(img_rows, img_cols),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed=GLOBAL_SEED\n)\n    \nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_path,\n    target_size=(img_rows, img_cols),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed=GLOBAL_SEED\n)   \n    \ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(img_rows, img_cols),\n    batch_size=batch_size,\n    class_mode=None,\n    seed=GLOBAL_SEED,\n    shuffle=False\n)\n\n# Pre-train model without augmentation\n\nmodel=create_model()\nmodel.fit(train_generator, epochs=EPOCHS_PRE_TRAIN, validation_data=validation_generator, \n        shuffle=True, verbose = 0)\npredictions_pretrain = model.predict(test_generator, verbose=0)\nmodel.save(model_path)\nr_prelim = calc_metrics(test_generator.classes, np.argmax(predictions_pretrain, axis=1), predictions_pretrain)\n\n\n# Pick images close to classification border of pretrained model\nborder_images, border_image_labels = pick_aug_images(model, train_generator, r_prelim, top_k = TOP_K)\ntf.keras.backend.clear_session()\nget_aug_images(border_images, border_image_labels, Y_train, train_path)\n    \n# New generators that include augmentation data\naug_train_datagen = ImageDataGenerator(validation_split=val_split)\naug_val_datagen = ImageDataGenerator(validation_split=val_split)\n    \naug_train_generator = aug_train_datagen.flow_from_directory(\n    train_path,\n    target_size=(img_rows, img_cols),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed=GLOBAL_SEED\n)\n    \naug_val_generator = aug_val_datagen.flow_from_directory(\n    validation_path,\n    target_size=(img_rows, img_cols),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed=GLOBAL_SEED\n)\n        \n# Train model on augmented dataset\naug_model = tf.keras.models.load_model(model_path)\n\nmc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, verbose = 0)\n\naug_model.fit(aug_train_generator, epochs=EPOCHS_TRAIN, validation_data=aug_val_generator, \n              shuffle=True, callbacks=[mc], verbose = 0)\naug_model = tf.keras.models.load_model(model_path)\npredictions = aug_model.predict(test_generator, verbose=0)\ny_pred = np.argmax(predictions, axis=1)\ntrue_classes = test_generator.classes\nres = calc_metrics(true_classes, y_pred, predictions)\nprint('Result: ' ,res)\n\n\nprint('')","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:57:53.818144Z","iopub.execute_input":"2022-06-08T09:57:53.818774Z"},"trusted":true},"execution_count":null,"outputs":[]}]}